{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO8YhcJuRw3pB+z9vzoO7AR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/makhthum/MDS_Deakin_SIG742/blob/main/sit742task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "![Deakin University](https://www.freelogovectors.net/svg11/deakin-university-logo_freelogovectors.net.svg)"
      ],
      "metadata": {
        "id": "FWN_kJeestKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Master of Data Science (MDS)\n",
        "###SIG 742 – Modern Data Science | Trimester 2, 2025\n",
        "####End Term Assesment 2025 - Group 1 - Team 6\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "OUDb_Mzlszfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Student Id   |     Student Name   \n",
        "S225450659   |     Syed. Makhthum Peera    "
      ],
      "metadata": {
        "id": "O1KOvuyntE3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 - Data Acquisition and Manipulation\n",
        "\n",
        "There are 8 questions in this part, totalling 60 marks. Each of question is worth 5 marks. Additionally, the quality of your explanation in both the report and video will collectively be worth 20 marks.   \n",
        "\n",
        "You are recommended to use Google Colab to finish all the coding in the code block cell, and provide sufficient coding comments, and also save the result of running as well.   \n",
        "\n",
        "The (business_review_submission.zip) data used for this part could be found in here. There are two files in the data. The first one is about the business review submission with many companies. For each of the row, the review submission is provided with relevant information such as user id, time, name and many others. The second one is the meta information of the business and the two data could be joined with gmap_id. You will need to use spark to first read the unzipped (csv) review data for starting and later join the meta review business data on dataframe (pandas or spark). You could find the code on reading csv data with Spark from M04G. In some of the tasks, if the question is not specifically asking to use spark, you could use both pandas and numpy."
      ],
      "metadata": {
        "id": "3hYK-Je3uYx1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1.1\n",
        "Using PySpark to do some data wrangling process, so that:   \n",
        "1.1.1 For the none or null in text column, change it to 'no review'.   \n",
        "1.1.2 Process the content in time column, and convert the strings from time to yyyy-mm-dd format in the new column as newtime and show the first 5 rows.  "
      ],
      "metadata": {
        "id": "zkIAsikMujrv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ans 1.1"
      ],
      "metadata": {
        "id": "sEYO1onLu0PW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J2tkvcicsfYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1.2\n",
        "Find out the information for gmap_id on the reviews. In order to achieve the above, some wrangling work is required to be done:   \n",
        "\n",
        "1.2.1 Using pyspark to calculate the number of reviews per each unique gmap_id and save as float format in pyspark dataframe to show the top 5 rows.   \n",
        "\n",
        "1.2.2 Transform the current pyspark dataframe to pandas dataframe (named as df) and create the column reivew_time with the information of review time on hours level. Print your df pandas dataframe with top 5 rows after creating the column review_time.   \n",
        "\n",
        "1.2.3 Using matplotlib or seaborn to draw some (two or more if possible) visualizations on the relationship between gmap_id and reivew_time. You could explore for example, what is the time people usually review? How many business is reviewed in the morning time etc. Please also discuss the insights you are finding with your visualizations in the markdown cell. Please also include your findings and visualizations in the report."
      ],
      "metadata": {
        "id": "P2xGqloQvPkz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ans 1.2"
      ],
      "metadata": {
        "id": "-25ZGkCEvPLn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NueOy3bIvbzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1.3\n",
        "\n",
        "Let’s continue to analyze the reivew_time with reviews and related gmap_id. You need to use another data meta-business to join with the current dataframe on gmap_id.   \n",
        "\n",
        "1.3.1 Determine which workday (day of the week), generates the most reviews (plotting the results in a line chart with workday on averaged submissions).\n",
        "\n",
        "1.3.2 Identify the names of business (column name from data meta-business) that has the highest averaged ratings on ‘that workday’ (you need to find out from 1.3.1), and find out which category those businesses are from?\n",
        "\n",
        "1.3.3 Please further explore the data on name of business and find out some more insights by yourself such as which category it is and what are the peak hours etc. Please use visualizations and tables to support your findings and write down the insights in the markdown cell. Please also include your findings and visualizations in the report."
      ],
      "metadata": {
        "id": "Jj7pUKW6vcuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ans 1.3"
      ],
      "metadata": {
        "id": "TbGrvhk9v05k"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lvzRqs4zvyRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1.4\n",
        "\n",
        "For the reviews on each of the submissions, work on all the review content and find out the top 30 most common words; Also generate separate word cloud visualizations for different years by grouping the reviews by review year and write down the insights in the markdown cell. Please also include your findings and visualizations in the report."
      ],
      "metadata": {
        "id": "If7xfQTDv79E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ans 1.4"
      ],
      "metadata": {
        "id": "H3nfPz7VwHfr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LBTH6X18vz2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q1.5\n",
        "Let’s do some analysis on the business_name and the reviewers. Determine the number of unique reviewers of business and its categories to identify which business / category has attracted the most reviewers (find out the highest distinct count of reviewers on business / category level). Also, analyze the temporal patterns of when reviewers submitted their reviews (you could leverage the workday, year, month, or hours to conduct the analysis) and share your findings and insights in the markdown cell. Please also include your findings and insights (visualizations) in the report."
      ],
      "metadata": {
        "id": "PlSaBIhvwKSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ans 1.5"
      ],
      "metadata": {
        "id": "rYejnVRwwOyl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QvNKktGmwOCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q1.6\n",
        "As the data scientist, you are required to build a recommendation for the business by using reviews, ratings, and its categories. In this task, you need to:\n",
        "\n",
        "1.6.1 Write down your strategy of building the recommendation on business for customers in the markdown cell. You could create your own strategy or leverage the provided one here KNN on collaborative filtering. Please also include your strategy details in the report.\n",
        "\n",
        "1.6.2 Could you please try to implement the strategy (code) you have written down for the recommendation system? Please give detailed explanation of your code and the logic in the comments and also interpret the recommendations with examples in the markdown cell. Please also include your implementation details and results in the report."
      ],
      "metadata": {
        "id": "cCddKKfBwRpq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ans 1.6"
      ],
      "metadata": {
        "id": "ZY8x8xr8wYdO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OZazDMDcwX16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q1.7\n",
        "\n",
        "Continue work on the review data you have now, for each of the submissions of the review, you will need to explore the rating with other information:\n",
        "\n",
        "1.7.1 Build visualization to explore the relationships of the rating and business categories. Please write down your insights in the markdown cell and also include your insights and visualizations in the report.\n",
        "\n",
        "1.7.2 Let’s focus on the lower ratings now. Could you please find out the actual reviews on lower ratings and analyze on the reason? (You could use the common used words in lower rating reviews or design your own strategy with reasonable logic). Please also include your analysis details in the report."
      ],
      "metadata": {
        "id": "yNXuak3bwaue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ans 1.7"
      ],
      "metadata": {
        "id": "1CYONWD6whzc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nPnO26SfwhXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q1.8\n",
        "\n",
        "Continue to work on the submission of the reviews, we would like to focus on the reviewer level with all the reviewed business history, but before we actually conduct the programming, we will need to finish few questions for exploration:\n",
        "\n",
        "1.8.1 Check on the reviewer level reviewed business, sort the review of each business by the review time (newtime column) and then save the business name into the list variable user_business_list for each reviewer.\n",
        "\n",
        "1.8.2 Check on the user_business_list, could you observe some repeated business names for the same user? If so, could you remove those duplicated business names under same user? Please print out the number of element in the user_business_list for each reviewer before removing the duplicated business name and after removing the duplicated business name.\n",
        "\n",
        "1.8.3 Check on the user_business_list, could you find the user similarities according to their past reviewed business ? You are free to design your own strategy and give sufficient explanation in markdown cell and code implementation together. Please also include your strategy details and implementation in the report.\n",
        "\n",
        "Hint: you might consider to use encoding for each of the business names and then calculate the difference of the users."
      ],
      "metadata": {
        "id": "vmVT5H5JwkE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ans 1.8"
      ],
      "metadata": {
        "id": "mHsVkB80wsBV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k4JG3Auswrj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2 - Submission Prediction\n",
        "\n",
        "There are 3 questions in this part, totaling 40 marks. Each question is worth 10 marks. Additionally, the quality of your explanation in both the report and video will collectively be worth 10 marks.  \n",
        "You are required to use Google Colab to finish all the coding in the code block cell, and provide sufficient coding comments, and also save the result of running as well."
      ],
      "metadata": {
        "id": "lvES2frhwwJk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q2.1\n",
        "\n",
        "In this question, we will focus only on two information: total reviews per day with review time (newtime from the dataframe) to form the review volume time series. You are required to explore the review time series. There are some days not available in the review time series. Please add those days into the review time series with default number of review with the mean value of the number of review per day in the whole data (without any filtering on reviews). After that, decompose the submission review time series with addictive mode and analyses on the results to find if there is any seasonality pattern (you could leverage the M05A material from lab session with default setting in seasonal_decompose function). Please also include your analysis details and implementation in the report."
      ],
      "metadata": {
        "id": "U4DvPYuOw5Fd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ans 2.1"
      ],
      "metadata": {
        "id": "8iYoDpOJw-iE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I03uHeM6wzs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q2.2\n",
        "\n",
        "We will try to use time series model ARIMA for forecasting the future. You need to find the best model with different parameters on ARIMA model. The parameter range for p,d,q are all from [0, 1, 2]. In total, you need to find out the best model with lowest Mean Absolute Error from 27 choices (you might need to split the time series to train and test with yourself with grid search according to the M05B material). Also, you are required to discuss with your group member on exploring the deep learning time series forecasting methods such as LSTM and RNN. Please write down your discussion around the necessary data wrangling and modeling steps (steps on how to achieve, not actual code). Also please give the reference of the deep learning time series forecasting models you are using. Please also include your discussion details and implementation in the report."
      ],
      "metadata": {
        "id": "tL6h2px5xASw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ans 2.2"
      ],
      "metadata": {
        "id": "HswIGZ2DxF1d"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_G5DAstBxE8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q2.3\n",
        "\n",
        "In this question, you are provided with the PDF file by Universities Australia via Indigenous Strategy annual report. You are required to critically analyze this report using your data science skills.\n",
        "\n",
        "**Data Extraction** Carefully review the PDF and identify all relevant quantitative data, tables, and figures that can be extracted or digitized; Present any extracted data in a structured format (e.g., CSV, Excel table, or DataFrame);\n",
        "\n",
        "**Data Analysis** Utilize your data analytics skills to discover common patterns or trends from the report; Where possible, compare trends over multiple years, between institutions, or across different Indigenous strategy metrics.\n",
        "\n",
        "**Insights** Provide a clear and concise summary of the main patterns, trends, or correlations discovered from your analysis; Interpret what these findings reveal about the progress and challenges of Indigenous strategies in Australian universities.\n",
        "\n",
        "You may use any data analytics tools or libraries you are comfortable with. All steps, from extraction to insights, should be clearly documented in your SIT742Task2Report.pdf, and source code should be in SIT742Task2Code.ipynb."
      ],
      "metadata": {
        "id": "V294Xp8IxIAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ans 2.3"
      ],
      "metadata": {
        "id": "ftmBXG5AxX7o"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "73zKL3CuxXbQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}